{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.4\n",
    "\n",
    "- *How is the reparametrisation trick handled in the code?*\n",
    "\n",
    "We use the `rsample` of the distribution from torch. (Explain more?)\n",
    "\n",
    "- *Consider the implementation of the ELBO. What are the dimensions of the inputs?* \n",
    "\n",
    "Both are the size of the batch, ie. 128.\n",
    "\n",
    "- *`torch.distributions.Independent` what does it do?* \n",
    "\n",
    "The `Independent` class does not represent any probability distribution. Instead, it creates a new distribution instance by “reinterpreting” some of the batch shapes of an existing distribution as event shapes.\n",
    "\n",
    "- *What is the purpose of the function `torch.chunk` in the `forward()` pass of the `GaussianEncoder`?*\n",
    "\n",
    "It splits the batch into a set amounts of chunks. So in the encoder's forward pass, we want to return an event of a Normal Distribution's parameters. Hence, it splits the incoming data into two batch chunks of 64 for estimating the mean and standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.5\n",
    "\n",
    "- *Evaluate the ELBO on the binarized MNIST test set*\n",
    "\n",
    "- *Plot samples from the approx. posterior and colour them by their correct class label. Implement it so if $M > 2$ a PCA is executed and plot the first two principal components.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
